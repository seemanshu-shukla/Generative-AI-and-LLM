- Note that here we are using Instance type: ml.m5.2xlarge which consists of 8vCPU+32 GiB RAM made availble through Amazon Sagemaker

- torch and torchdata will be help in pytorch data loading

- evaluate and rouge_score for embedding the evaluation metrices

- loralib and peft to implement LoRA and PEFT concepts

- AutoModelForSeq2SeqLM will give us access to FLAN-T5 LLM

- We are naming a variable as original_model since this will be later used to evaluate the performance later b/w base full fine tuned and PEFT

- def print_number_of_trainable_model_parameters(model)
is the function that will print all the trinable prarameters

- tokenize_function is the function for our convience to wrap the dataset into prompts with instruction will be used for instruction fine tuning later

- We are actually goining to filer out the the dataset that is goining to use a subset or subsample of the dataset dialogsum in order to save time, memory and compute during the fine tuning process

- Checking shape of resultant subsample of original dataset

- Here just to save time we have used very low value of num_train_epochs, weight_decay, max_steps etc which are all the hyperparameter. Later Instrctor said that he will be showing that how in offline using huge memory resources and using much larger values of these hyperparameters LLMs are trained in the real time

- Pulling already full trained model from s3 object storage. We are doing this as if we start fine traning at real time it will take a lot of time. So, in the intrest of time we are downloading the already fully fine tuned model which is of size 945 Megabytes or apporx 1GB

- The full fine tuned instruct model is downloaded from s3 storage object and stored in this folder ./flan-dialogue-summary-checkpoint

- Evaluating model using Qualitative appraoch (that is checking performace by compare models performace for a single record using human intelligence)

- Evaluating model using Quantitative approach using ROUGE. We are using first 10 elements from our Test Dataset for calculating the ROUGE score for the model

- Instructor told that in offline he did not calculated the Rouge score on just 10 or 15 example but on a much larger test dataset that is .csv file placed in the data directory

- Again for demonstration purpose we have taken small number of epochs and small number of steps in the PEFT

- For PEFT fine tuned model Orginal one was trained offline which in this lab in downloaded from s3 bucket storage which is of size 14208525 bits or 14 MB(mega bytes) which is much lower as compared to the size of fully fine tuned model having the size of approx 1 GB. This PEFT version goining forward will get merged or combined with the original LLM enabling instruction fine tuning

- To summarize we are goining to merge the PEFT version (named as PEFT adapter by instructor) with orginal FLAN-T5 model and then we are goining to perform the required summarization task using dialogsum dataset that is converted into instruction prompts. This is how fine tuning (instruction fine tuning) is being done in the case of PEFT using LoRA

- VVV. Imp: 
SWITCHING IN AND OUT B/W DIFFERENT TASK: 
I can actually set the is_trainable flag to false. By setting the is_trainable flag to false, we are telling PyTorch that we're not interested in training this model. All we're interested in doing is the forward pass just to get the summaries(This is what meant when instructor says that we are only planning to perform inference with the PEFT model). This is significant because we can tell PyTorch to not load any of the update portions of these operators and to basically minimize the footprint needed to just perform the inference with this model. This is a pretty neat flag. This was actually just introduced recently into the PEFT model at the time of this lab. I wanted to show it here because this is a pattern that you want to try to find when you're doing your own modeling. When you know that you're ready to deploy the model for inference, there are usually ways that you can hint to the framework, such as PyTorch that you're not going to be training. This can then further reduce the resources needed to make these predictions. 

- For Qualitative or human evaluation we have randomly picked 200th index record from test dataset

- Qualitaively is we see the will find that PEFT is a little but generating different nuance(a small difference) as compared summary generated by Full Fine tuned model and Original Base model (Here we have used FLAN-T5 model)

- But when we perform the same quantitively using ROUGE matrix then will find that there is a very little difference or a bit degradation as compared to Full fine tuned. Not too bad but we used much much less resources during fine tuning using PEFT than we would have done using full instruction fine tuning

- 
